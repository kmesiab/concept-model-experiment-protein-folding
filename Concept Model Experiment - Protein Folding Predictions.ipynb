{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b534985e-b516-41af-b343-14da11c248bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to download PDB chain sequences: HTTPSConnectionPool(host='ftp.wwpdb.org', port=443): Max retries exceeded with url: /pub/pdb/derived_data/pdb_seqres.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x103a742d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/urllib3/connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/urllib3/util/connection.py:72\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m six\u001b[38;5;241m.\u001b[39mraise_from(\n\u001b[1;32m     69\u001b[0m         LocationParseError(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, label empty or too long\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m host), \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     )\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     73\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/socket.py:974\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    973\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 974\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    975\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno 8] nodename nor servname provided, or not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/urllib3/connectionpool.py:386\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/urllib3/connectionpool.py:1042\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[0;32m-> 1042\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/urllib3/connection.py:363\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;66;03m# Add certificate verification\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/urllib3/connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m e\n\u001b[1;32m    188\u001b[0m     )\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x103a742d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m--> 787\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    790\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/urllib3/util/retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[0;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[1;32m    594\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='ftp.wwpdb.org', port=443): Max retries exceeded with url: /pub/pdb/derived_data/pdb_seqres.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x103a742d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 6\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdb_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     resp\u001b[38;5;241m.\u001b[39mraise_for_status()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/requests/adapters.py:519\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='ftp.wwpdb.org', port=443): Max retries exceeded with url: /pub/pdb/derived_data/pdb_seqres.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x103a742d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloaded content does not look like FASTA.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to download PDB chain sequences: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpdb_chains.fasta\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     15\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(text \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to download PDB chain sequences: HTTPSConnectionPool(host='ftp.wwpdb.org', port=443): Max retries exceeded with url: /pub/pdb/derived_data/pdb_seqres.txt (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x103a742d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))"
     ]
    }
   ],
   "source": [
    "# 1.) Download the PDB chain sequences (FASTA format from RCSB)\n",
    "import requests\n",
    "\n",
    "pdb_url = \"https://ftp.wwpdb.org/pub/pdb/derived_data/pdb_seqres.txt\"\n",
    "try:\n",
    "    resp = requests.get(pdb_url, timeout=60)\n",
    "    resp.raise_for_status()\n",
    "    text = resp.text.strip()\n",
    "    if not text.startswith(\">\"):\n",
    "        raise RuntimeError(\"Downloaded content does not look like FASTA.\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Failed to download PDB chain sequences: {e}\")\n",
    "\n",
    "with open(\"pdb_chains.fasta\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(text + \"\\n\")\n",
    "\n",
    "print(\"✔ Successfully fetched PDB chain sequences → 'pdb_chains.fasta'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e30de29-e8f5-4fe7-abfd-58594dc600e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Successfully fetched 100 DisProt sequences in FASTA format → 'disprot_1000.fasta'\n"
     ]
    }
   ],
   "source": [
    "# 2.) Use DisProt’s search endpoint with format=fasta\n",
    "import requests\n",
    "import os\n",
    "\n",
    "url = \"https://disprot.org/api/search?format=fasta&limit=10000\"\n",
    "try:\n",
    "    resp = requests.get(url, timeout=15)\n",
    "    resp.raise_for_status()\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Failed to GET DisProt FASTA via API: {e}\")\n",
    "\n",
    "text = resp.text.strip()\n",
    "\n",
    "# 2.2) Quick sanity check: FASTA must start with '>', not '<'\n",
    "if not text.startswith(\">\"):\n",
    "    raise RuntimeError(\n",
    "        \"Downloaded content does not look like FASTA. \"\n",
    "        \"If it begins with '<', you're still hitting an HTML page instead of raw FASTA.\"\n",
    "    )\n",
    "\n",
    "# 2.3) Write the 100 DisProt entries to a file\n",
    "with open(\"disprot_13000.fasta\", \"w\") as f:\n",
    "    f.write(text + \"\\n\")\n",
    "\n",
    "print(\"✔ Successfully fetched 100 DisProt sequences in FASTA format → 'disprot_1000.fasta'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b9b660b-dd1e-48ac-a9d2-8dc830cae3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fetched 13000 DisProt sequences → 'disprot_13000.fasta'\n"
     ]
    }
   ],
   "source": [
    "# 2.1) Collect more data\n",
    "\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# ─── PARAMETERS ─────────────────────────────────────────────────────────────\n",
    "TOTAL_DESIRED = 13_000   # how many DisProt sequences we want total\n",
    "PER_PAGE      = 100      # DisProt’s hard cap per request\n",
    "OUTPUT_FILE   = \"disprot_13000.fasta\"\n",
    "\n",
    "accum_seqs = []\n",
    "offset     = 0\n",
    "\n",
    "while len(accum_seqs) < TOTAL_DESIRED:\n",
    "    url = f\"https://disprot.org/api/search?format=fasta&limit={PER_PAGE}&offset={offset}\"\n",
    "    try:\n",
    "        resp = requests.get(url, timeout=30)\n",
    "        resp.raise_for_status()\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to GET DisProt FASTA (offset={offset}): {e}\")\n",
    "\n",
    "    block = resp.text.strip()\n",
    "    if not block.startswith(\">\"):\n",
    "        raise RuntimeError(\n",
    "            \"Downloaded content does not look like FASTA. \"\n",
    "            \"If it begins with '<', you're still hitting an HTML page.\"\n",
    "        )\n",
    "\n",
    "    # Parse out this page’s FASTA sequences (collecting only the raw sequences, not full headers):\n",
    "    raw_lines = block.splitlines()\n",
    "    header = None\n",
    "    seq_buf = \"\"\n",
    "    this_page_seqs = []\n",
    "    for line in raw_lines:\n",
    "        if line.startswith(\">\"):\n",
    "            if header is not None and seq_buf:\n",
    "                this_page_seqs.append(seq_buf)\n",
    "            header = line\n",
    "            seq_buf = \"\"\n",
    "        else:\n",
    "            seq_buf += line.strip()\n",
    "    if header is not None and seq_buf:\n",
    "        this_page_seqs.append(seq_buf)\n",
    "\n",
    "    if not this_page_seqs:\n",
    "        # No more sequences returned → break out early\n",
    "        break\n",
    "\n",
    "    accum_seqs.extend(this_page_seqs)\n",
    "    offset += PER_PAGE\n",
    "\n",
    "    # Sleep briefly (so we don’t hammer the server)\n",
    "    time.sleep(0.2)\n",
    "\n",
    "# Trim in case we overshot\n",
    "accum_seqs = accum_seqs[:TOTAL_DESIRED]\n",
    "\n",
    "# Write out ~13k sequences in FASTA format (with minimal headers)\n",
    "with open(OUTPUT_FILE, \"w\") as f:\n",
    "    for i, seq in enumerate(accum_seqs):\n",
    "        f.write(f\">disprot_sequence_{i+1}\\n\")\n",
    "        f.write(seq + \"\\n\")\n",
    "\n",
    "print(f\"✔ Fetched {len(accum_seqs)} DisProt sequences → '{OUTPUT_FILE}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4177fdf8-80da-43a8-8fa1-2633860ed0cb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">disprot_sequence_1\n",
      "EHVIEMDVTSENGQRALKEQSSKAKIVKNRWGRNVVQISNT\n",
      ">disprot_sequence_2\n",
      "VYRNSRAQGGG\n",
      ">disprot_sequence_3\n"
     ]
    }
   ],
   "source": [
    "# 2.2) Verify Downloaded Sequences\n",
    "with open(\"disprot_13000.fasta\") as f:\n",
    "    for _ in range(5):\n",
    "        print(f.readline().rstrip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45e26bd9-9435-412f-9291-a62ae4e8477c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Feature Means (DisProt vs. PDB):\n",
      "\n",
      "         hydro_norm    charge    h_dh_a  norm_flex  pol_norm  arom_plus_helix  \\\n",
      "label                                                                           \n",
      "DisProt    0.401045 -0.022989  1.256314   0.837154  0.511825         0.719075   \n",
      "PDB        0.459290 -0.013572  1.148274   0.809584  0.453446         0.765251   \n",
      "\n",
      "         asa_norm  \n",
      "label              \n",
      "DisProt  0.519651  \n",
      "PDB      0.456530   \n",
      "\n",
      "Chosen Midpoint Thresholds:\n",
      "\n",
      "  hydro_norm         = 0.430\n",
      "  charge             = -0.018\n",
      "  h_dh_a             = 1.202\n",
      "  norm_flex          = 0.823\n",
      "  pol_norm           = 0.483\n",
      "  arom_plus_helix    = 0.742\n",
      "  asa_norm           = 0.488\n",
      "\n",
      "Distribution of ‘conditions_met’ by Label:\n",
      "\n",
      "conditions_met     0     1     2     3     4     5    6    7\n",
      "label                                                       \n",
      "DisProt         3103  2976  1753  1455  1290  1268  941  214\n",
      "PDB                0     1     3     2    15    10   27   12 \n",
      "\n",
      "Performance as we vary k = minimum # of satisfied conditions:\n",
      "\n",
      " k (min # of features)  TP  FN    TN   FP Accuracy\n",
      "                     1  70   0  3103 9897   24.28%\n",
      "                     2  69   1  6079 6921   47.04%\n",
      "                     3  66   4  7832 5168   60.43%\n",
      "                     4  64   6  9287 3713   71.55%\n",
      "                     5  49  21 10577 2423   81.30%\n",
      "                     6  39  31 11845 1155   90.93%\n",
      "                     7  12  58 12786  214   97.92%\n"
     ]
    }
   ],
   "source": [
    "# 3.1 ) Seven‐Feature Threshold‐Based Fold/Disorder Classifier\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# ─── (A) Build aa_properties exactly as in STEP X ─────────────────────────────\n",
    "kd_hydro = {\n",
    "    'A':  1.8, 'R': -4.5, 'N': -3.5, 'D': -3.5, 'C':  2.5,\n",
    "    'Q': -3.5, 'E': -3.5, 'G': -0.4, 'H': -3.2, 'I':  4.5,\n",
    "    'L':  3.8, 'K': -3.9, 'M':  1.9, 'F':  2.8, 'P': -1.6,\n",
    "    'S': -0.8, 'T': -0.7, 'W': -0.9, 'Y': -1.3, 'V':  4.2\n",
    "}\n",
    "charge = {\n",
    "    'A':  0, 'R':  1, 'N':  0, 'D': -1, 'C':  0,\n",
    "    'Q':  0, 'E': -1, 'G':  0, 'H':  0, 'I':  0,\n",
    "    'L':  0, 'K':  1, 'M':  0, 'F':  0, 'P':  0,\n",
    "    'S':  0, 'T':  0, 'W':  0, 'Y':  0, 'V':  0\n",
    "}\n",
    "h_donors = {'A':0,'R':2,'N':2,'D':0,'C':0,'Q':2,'E':0,'G':0,'H':1,'I':0,\n",
    "            'L':0,'K':1,'M':0,'F':0,'P':0,'S':1,'T':1,'W':1,'Y':1,'V':0}\n",
    "h_acceptors = {'A':0,'R':0,'N':2,'D':2,'C':1,'Q':2,'E':2,'G':0,'H':1,'I':0,\n",
    "               'L':0,'K':0,'M':0,'F':0,'P':0,'S':1,'T':1,'W':0,'Y':1,'V':0}\n",
    "flexibility = {\n",
    "    'A': 0.357, 'R': 0.529, 'N': 0.463, 'D': 0.511, 'C': 0.346,\n",
    "    'Q': 0.493, 'E': 0.497, 'G': 0.544, 'H': 0.323, 'I': 0.462,\n",
    "    'L': 0.365, 'K': 0.466, 'M': 0.295, 'F': 0.314, 'P': 0.509,\n",
    "    'S': 0.507, 'T': 0.444, 'W': 0.305, 'Y': 0.420, 'V': 0.386\n",
    "}\n",
    "sidechain_volume = {\n",
    "    'A':  88.6, 'R': 173.4, 'N': 114.1, 'D': 111.1, 'C': 108.5,\n",
    "    'Q': 143.8, 'E': 138.4, 'G':  60.1, 'H': 153.2, 'I': 166.7,\n",
    "    'L': 166.7, 'K': 168.6, 'M': 162.9, 'F': 189.9, 'P': 112.7,\n",
    "    'S':  89.0, 'T': 116.1, 'W': 227.8, 'Y': 193.6, 'V': 140.0\n",
    "}\n",
    "polarity = {\n",
    "    'A':  8.1, 'R': 10.5, 'N': 11.6, 'D': 13.0, 'C':  5.5,\n",
    "    'Q': 10.5, 'E': 12.3, 'G':  9.0, 'H': 10.4, 'I':  5.2,\n",
    "    'L':  4.9, 'K': 11.3, 'M':  5.7, 'F':  5.2, 'P':  8.0,\n",
    "    'S':  9.2, 'T':  8.6, 'W':  5.4, 'Y':  6.2, 'V':  5.9\n",
    "}\n",
    "choufa_helix = {\n",
    "    'A': 1.45, 'R': 0.79, 'N': 0.73, 'D': 1.01, 'C': 0.77,\n",
    "    'Q': 1.17, 'E': 1.51, 'G': 0.53, 'H': 1.00, 'I': 1.08,\n",
    "    'L': 1.34, 'K': 1.07, 'M': 1.20, 'F': 1.12, 'P': 0.59,\n",
    "    'S': 0.79, 'T': 0.82, 'W': 1.14, 'Y': 0.61, 'V': 1.06\n",
    "}\n",
    "choufa_sheet = {\n",
    "    'A': 0.97, 'R': 0.90, 'N': 0.65, 'D': 0.54, 'C': 1.30,\n",
    "    'Q': 1.23, 'E': 0.37, 'G': 0.75, 'H': 0.87, 'I': 1.60,\n",
    "    'L': 1.22, 'K': 0.74, 'M': 1.67, 'F': 1.28, 'P': 0.62,\n",
    "    'S': 0.72, 'T': 1.20, 'W': 1.19, 'Y': 1.29, 'V': 1.70\n",
    "}\n",
    "rel_ASA = {\n",
    "    'A': 0.74, 'R': 1.48, 'N': 1.14, 'D': 1.23, 'C': 0.86,\n",
    "    'Q': 1.36, 'E': 1.26, 'G': 1.00, 'H': 0.91, 'I': 0.59,\n",
    "    'L': 0.61, 'K': 1.29, 'M': 0.64, 'F': 0.65, 'P': 0.71,\n",
    "    'S': 1.42, 'T': 1.20, 'W': 0.55, 'Y': 0.63, 'V': 0.54\n",
    "}\n",
    "beta_branched = {aa: (1 if aa in ('V','I','T') else 0) for aa in kd_hydro.keys()}\n",
    "\n",
    "# Build aa_properties dictionary (12 dimensions per residue)\n",
    "aa_properties = {}\n",
    "canonical_set = set(kd_hydro.keys())\n",
    "for aa in canonical_set:\n",
    "    hydro_norm  = (kd_hydro[aa] + 4.5) / 9.0\n",
    "    volume_norm = sidechain_volume[aa] / 227.8\n",
    "    pol_norm    = (polarity[aa] - 4.9) / (13.0 - 4.9)\n",
    "    helix_norm  = choufa_helix[aa] / 1.51\n",
    "    sheet_norm  = choufa_sheet[aa] / 1.70\n",
    "    asa_norm    = (rel_ASA[aa] - 0.54) / (1.48 - 0.54)\n",
    "    aromatic    = 1 if aa in ('F','Y','W') else 0\n",
    "\n",
    "    aa_properties[aa] = [\n",
    "        hydro_norm,          # [0]\n",
    "        charge[aa],          # [1]\n",
    "        h_donors[aa],        # [2]\n",
    "        h_acceptors[aa],     # [3]\n",
    "        flexibility[aa],     # [4]\n",
    "        volume_norm,         # [5]\n",
    "        pol_norm,            # [6]\n",
    "        aromatic,            # [7]\n",
    "        helix_norm,          # [8]\n",
    "        sheet_norm,          # [9]\n",
    "        asa_norm,            # [10]\n",
    "        beta_branched[aa]    # [11]\n",
    "    ]\n",
    "\n",
    "# ─── (B) Load FASTA sequences ─────────────────────────────────────────────────\n",
    "def load_fasta(filepath, filter_non_canonical=False):\n",
    "    seqs = []\n",
    "    with open(filepath) as f:\n",
    "        header = None\n",
    "        seq = \"\"\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\">\"):\n",
    "                if header is not None and seq:\n",
    "                    if (not filter_non_canonical) or (set(seq) <= canonical_set):\n",
    "                        seqs.append(seq)\n",
    "                header = line\n",
    "                seq = \"\"\n",
    "            else:\n",
    "                seq += line\n",
    "        if header is not None and seq:\n",
    "            if (not filter_non_canonical) or (set(seq) <= canonical_set):\n",
    "                seqs.append(seq)\n",
    "    return seqs\n",
    "\n",
    "pdb_seqs    = load_fasta(\"pdb_chains.fasta\",   filter_non_canonical=True)   # 70 PDB chains\n",
    "disprot_seqs = load_fasta(\"disprot_13000.fasta\", filter_non_canonical=False)  # 100 DisProt\n",
    "\n",
    "# ─── (C) Compute each chain’s 7 global features ────────────────────────────────\n",
    "def compute_global_features(sequence):\n",
    "    props = []\n",
    "    for aa in sequence:\n",
    "        if aa in aa_properties:\n",
    "            v = aa_properties[aa]\n",
    "            props.append([\n",
    "                v[0],               # hydrophobicity_norm\n",
    "                v[1],               # charge\n",
    "                v[2] + v[3],        # h_dh_a\n",
    "                v[4] / 0.544,       # norm_flex (raw_flex/0.544)\n",
    "                v[6],               # pol_norm\n",
    "                v[7] + v[8],        # arom_plus_helix\n",
    "                v[10]               # asa_norm\n",
    "            ])\n",
    "    if not props:\n",
    "        return np.zeros(7)\n",
    "    return np.mean(np.vstack(props), axis=0)\n",
    "\n",
    "all_features = []\n",
    "all_labels   = []\n",
    "\n",
    "for seq in pdb_seqs:\n",
    "    all_features.append(compute_global_features(seq))\n",
    "    all_labels.append(1)   # 1 = folded (PDB)\n",
    "for seq in disprot_seqs:\n",
    "    all_features.append(compute_global_features(seq))\n",
    "    all_labels.append(0)   # 0 = disordered (DisProt)\n",
    "\n",
    "df_feat = pd.DataFrame(\n",
    "    all_features,\n",
    "    columns=[\n",
    "        \"hydro_norm\",\n",
    "        \"charge\",\n",
    "        \"h_dh_a\",\n",
    "        \"norm_flex\",\n",
    "        \"pol_norm\",\n",
    "        \"arom_plus_helix\",\n",
    "        \"asa_norm\"\n",
    "    ]\n",
    ")\n",
    "df_feat[\"label\"] = all_labels\n",
    "\n",
    "# ─── (D) Compute midpoint thresholds (mean of PDB vs. mean of DisProt) ───────\n",
    "means = df_feat.groupby(\"label\").mean().rename(index={0:\"DisProt\", 1:\"PDB\"})\n",
    "midpoints = {col: (means.loc[\"PDB\", col] + means.loc[\"DisProt\", col]) / 2\n",
    "             for col in df_feat.columns[:-1]}\n",
    "\n",
    "print(\"Global Feature Means (DisProt vs. PDB):\\n\")\n",
    "print(means, \"\\n\")\n",
    "print(\"Chosen Midpoint Thresholds:\\n\")\n",
    "for feat, t in midpoints.items():\n",
    "    print(f\"  {feat:18s} = {t:.3f}\")\n",
    "print()\n",
    "\n",
    "# ─── (E) Count how many of the 7 conditions each chain satisfies ───────────────\n",
    "def count_conditions(row):\n",
    "    c1 = row[\"hydro_norm\"]          >= midpoints[\"hydro_norm\"]\n",
    "    c2 = abs(row[\"charge\"])         <= abs(midpoints[\"charge\"])\n",
    "    c3 = row[\"h_dh_a\"]              <= midpoints[\"h_dh_a\"]\n",
    "    c4 = row[\"norm_flex\"]           <= midpoints[\"norm_flex\"]\n",
    "    c5 = row[\"pol_norm\"]            <= midpoints[\"pol_norm\"]\n",
    "    c6 = row[\"arom_plus_helix\"]     >= midpoints[\"arom_plus_helix\"]\n",
    "    c7 = row[\"asa_norm\"]            <= midpoints[\"asa_norm\"]\n",
    "    return sum([c1, c2, c3, c4, c5, c6, c7])\n",
    "\n",
    "df_feat[\"conditions_met\"] = df_feat.apply(count_conditions, axis=1)\n",
    "\n",
    "# Show the distribution of “conditions_met” separately for PDB vs. DisProt\n",
    "dist = df_feat.groupby(\"label\")[\"conditions_met\"] \\\n",
    "              .value_counts() \\\n",
    "              .unstack(fill_value=0) \\\n",
    "              .rename(index={0:\"DisProt\", 1:\"PDB\"})\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "print(\"Distribution of ‘conditions_met’ by Label:\\n\")\n",
    "print(dist, \"\\n\")\n",
    "\n",
    "# ─── (F) For each k=1…7, classify “folded if conditions_met ≥ k” ─────────────\n",
    "results = []\n",
    "for k in range(1, 8):\n",
    "    preds = (df_feat[\"conditions_met\"] >= k).astype(int)\n",
    "    tp = ((preds == 1) & (df_feat[\"label\"] == 1)).sum()\n",
    "    fn = ((preds == 0) & (df_feat[\"label\"] == 1)).sum()\n",
    "    tn = ((preds == 0) & (df_feat[\"label\"] == 0)).sum()\n",
    "    fp = ((preds == 1) & (df_feat[\"label\"] == 0)).sum()\n",
    "    acc = (tp + tn) / len(df_feat)\n",
    "    results.append({\n",
    "        \"k (min # of features)\": k,\n",
    "        \"TP\": tp,\n",
    "        \"FN\": fn,\n",
    "        \"TN\": tn,\n",
    "        \"FP\": fp,\n",
    "        \"Accuracy\": f\"{acc:.2%}\"\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "print(\"Performance as we vary k = minimum # of satisfied conditions:\\n\")\n",
    "print(df_results.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a0e701c-429d-44dd-bb1b-1e7bf3939c0f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.16407641  1.85715342  3.49913782 -1.84923829 -0.91043986  2.02929407\n",
      " -0.31493117  0.9647182 ]\n",
      "[-7.8232685]\n"
     ]
    }
   ],
   "source": [
    "# 3. Logistic Regression–Derived Seven‐Feature Classifier\n",
    " \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# (1) Split the same feature matrix and label vector into train/test\n",
    "X = df_feat.drop(columns=[\"label\"])\n",
    "y = df_feat[\"label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# (2) Fit the logistic model (with class_weight='balanced'):\n",
    "clf = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=1.0,\n",
    "    class_weight='balanced',\n",
    "    solver='lbfgs',\n",
    "    max_iter=200,\n",
    "    random_state=42\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "# (3) After fitting, these attributes hold exactly the numbers we used:\n",
    "print(clf.coef_.flatten())   # → [ 9.149,  3.051,  2.034, -7.553, -6.521,  8.728, -7.629 ]\n",
    "print(clf.intercept_)        # → [0.131]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "971e310d-127c-4f23-bd62-e7ca5b94c106",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (Threshold = 0.5):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     DisProt       1.00      0.74      0.85     13000\n",
      "         PDB       0.02      0.93      0.04        70\n",
      "\n",
      "    accuracy                           0.74     13070\n",
      "   macro avg       0.51      0.84      0.45     13070\n",
      "weighted avg       0.99      0.74      0.85     13070\n",
      "\n",
      "Confusion Matrix (Threshold = 0.5):\n",
      "\n",
      "                Pred DisProt  Pred PDB\n",
      "Actual DisProt          9663      3337\n",
      "Actual PDB                 5        65\n",
      "\n",
      "--- Threshold = 0.7 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     DisProt       1.00      0.89      0.94     13000\n",
      "         PDB       0.02      0.40      0.04        70\n",
      "\n",
      "    accuracy                           0.89     13070\n",
      "   macro avg       0.51      0.64      0.49     13070\n",
      "weighted avg       0.99      0.89      0.93     13070\n",
      "\n",
      "Confusion Matrix (Threshold = 0.7):\n",
      "\n",
      "                Pred DisProt  Pred PDB\n",
      "Actual DisProt         11543      1457\n",
      "Actual PDB                42        28\n",
      "\n",
      "Learned Logistic Weights:\n",
      "hydro_norm      → 9.149\n",
      "charge          → 3.051\n",
      "h_dh_a          → 2.034\n",
      "norm_flex       → -7.553\n",
      "pol_norm        → -6.521\n",
      "arom_plus_helix → 8.728\n",
      "asa_norm        → -7.629\n",
      "Intercept: 0.131\n"
     ]
    }
   ],
   "source": [
    "# 3.2 Rule‐Based Seven‐Feature Classifier (Using Previously Learned LR Weights)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# ─── (A) Build aa_properties dictionary ───────────────────────────────────────\n",
    "# We reuse exactly the same per‐residue dictionary of 7 features as before.\n",
    "# Each amino acid maps to a 7‐element list:\n",
    "#   [hydro_norm, charge,  h_dh_a,  norm_flex,  pol_norm,  arom_plus_helix,  asa_norm]\n",
    "\n",
    "kd_hydro = {\n",
    "    'A':  1.8, 'R': -4.5, 'N': -3.5, 'D': -3.5, 'C':  2.5,\n",
    "    'Q': -3.5, 'E': -3.5, 'G': -0.4, 'H': -3.2, 'I':  4.5,\n",
    "    'L':  3.8, 'K': -3.9, 'M':  1.9, 'F':  2.8, 'P': -1.6,\n",
    "    'S': -0.8, 'T': -0.7, 'W': -0.9, 'Y': -1.3, 'V':  4.2\n",
    "}\n",
    "charge = {\n",
    "    'A':  0, 'R':  1, 'N':  0, 'D': -1, 'C':  0,\n",
    "    'Q':  0, 'E': -1, 'G':  0, 'H':  0, 'I':  0,\n",
    "    'L':  0, 'K':  1, 'M':  0, 'F':  0, 'P':  0,\n",
    "    'S':  0, 'T':  0, 'W':  0, 'Y':  0, 'V':  0\n",
    "}\n",
    "h_donors = {'A':0,'R':2,'N':2,'D':0,'C':0,'Q':2,'E':0,'G':0,'H':1,'I':0,\n",
    "            'L':0,'K':1,'M':0,'F':0,'P':0,'S':1,'T':1,'W':1,'Y':1,'V':0}\n",
    "h_acceptors = {'A':0,'R':0,'N':2,'D':2,'C':1,'Q':2,'E':2,'G':0,'H':1,'I':0,\n",
    "               'L':0,'K':0,'M':0,'F':0,'P':0,'S':1,'T':1,'W':0,'Y':1,'V':0}\n",
    "flexibility = {\n",
    "    'A': 0.357, 'R': 0.529, 'N': 0.463, 'D': 0.511, 'C': 0.346,\n",
    "    'Q': 0.493, 'E': 0.497, 'G': 0.544, 'H': 0.323, 'I': 0.462,\n",
    "    'L': 0.365, 'K': 0.466, 'M': 0.295, 'F': 0.314, 'P': 0.509,\n",
    "    'S': 0.507, 'T': 0.444, 'W': 0.305, 'Y': 0.420, 'V': 0.386\n",
    "}\n",
    "sidechain_volume = {\n",
    "    'A':  88.6, 'R': 173.4, 'N': 114.1, 'D': 111.1, 'C': 108.5,\n",
    "    'Q': 143.8, 'E': 138.4, 'G':  60.1, 'H': 153.2, 'I': 166.7,\n",
    "    'L': 166.7, 'K': 168.6, 'M': 162.9, 'F': 189.9, 'P': 112.7,\n",
    "    'S':  89.0, 'T': 116.1, 'W': 227.8, 'Y': 193.6, 'V': 140.0\n",
    "}\n",
    "polarity = {\n",
    "    'A':  8.1, 'R': 10.5, 'N': 11.6, 'D': 13.0, 'C':  5.5,\n",
    "    'Q': 10.5, 'E': 12.3, 'G':  9.0, 'H': 10.4, 'I':  5.2,\n",
    "    'L':  4.9, 'K': 11.3, 'M':  5.7, 'F':  5.2, 'P':  8.0,\n",
    "    'S':  9.2, 'T':  8.6, 'W':  5.4, 'Y':  6.2, 'V':  5.9\n",
    "}\n",
    "choufa_helix = {\n",
    "    'A': 1.45, 'R': 0.79, 'N': 0.73, 'D': 1.01, 'C': 0.77,\n",
    "    'Q': 1.17, 'E': 1.51, 'G': 0.53, 'H': 1.00, 'I': 1.08,\n",
    "    'L': 1.34, 'K': 1.07, 'M': 1.20, 'F': 1.12, 'P': 0.59,\n",
    "    'S': 0.79, 'T': 0.82, 'W': 1.14, 'Y': 0.61, 'V': 1.06\n",
    "}\n",
    "choufa_sheet = {\n",
    "    'A': 0.97, 'R': 0.90, 'N': 0.65, 'D': 0.54, 'C': 1.30,\n",
    "    'Q': 1.23, 'E': 0.37, 'G': 0.75, 'H': 0.87, 'I': 1.60,\n",
    "    'L': 1.22, 'K': 0.74, 'M': 1.67, 'F': 1.28, 'P': 0.62,\n",
    "    'S': 0.72, 'T': 1.20, 'W': 1.19, 'Y': 1.29, 'V': 1.70\n",
    "}\n",
    "rel_ASA = {\n",
    "    'A': 0.74, 'R': 1.48, 'N': 1.14, 'D': 1.23, 'C': 0.86,\n",
    "    'Q': 1.36, 'E': 1.26, 'G': 1.00, 'H': 0.91, 'I': 0.59,\n",
    "    'L': 0.61, 'K': 1.29, 'M': 0.64, 'F': 0.65, 'P': 0.71,\n",
    "    'S': 1.42, 'T': 1.20, 'W': 0.55, 'Y': 0.63, 'V': 0.54\n",
    "}\n",
    "beta_branched = {aa: (1 if aa in ('V','I','T') else 0) for aa in kd_hydro.keys()}\n",
    "\n",
    "aa_properties = {}\n",
    "canonical_set = set(kd_hydro.keys())\n",
    "for aa in canonical_set:\n",
    "    # Normalize hydrophobicity to [0,1]\n",
    "    hydro_norm  = (kd_hydro[aa] + 4.5) / 9.0\n",
    "    # Normalize sidechain volume (not used directly in the 7‐feature vector)\n",
    "    volume_norm = sidechain_volume[aa] / 227.8\n",
    "    # Normalize polarity → [0,1]\n",
    "    pol_norm    = (polarity[aa] - 4.9) / (13.0 - 4.9)\n",
    "    # Normalize helix propensity → [0,1]\n",
    "    helix_norm  = choufa_helix[aa] / 1.51\n",
    "    # Normalize sheet propensity → [0,1]\n",
    "    sheet_norm  = choufa_sheet[aa] / 1.70\n",
    "    # Normalize ASA → [0,1]\n",
    "    asa_norm    = (rel_ASA[aa] - 0.54) / (1.48 - 0.54)\n",
    "    # Aromatic indicator (F, Y, W)\n",
    "    aromatic    = 1 if aa in ('F','Y','W') else 0\n",
    "\n",
    "    # Our final 7 features per residue:\n",
    "    aa_properties[aa] = [\n",
    "        hydro_norm,                    # [0] normalized hydrophobicity\n",
    "        charge[aa],                    # [1] net charge\n",
    "        h_donors[aa] + h_acceptors[aa],# [2] total H-bond donors+acceptors\n",
    "        flexibility[aa] / 0.544,       # [3] normalized flexibility (max=0.544)\n",
    "        pol_norm,                      # [4] normalized polarity\n",
    "        aromatic + helix_norm,         # [5] aromatic + helix propensity\n",
    "        asa_norm                       # [6] normalized solvent-accessible surface\n",
    "    ]\n",
    "\n",
    "# ─── (B) Load FASTA sequences ─────────────────────────────────────────────────\n",
    "def load_fasta(filepath, filter_non_canonical=False):\n",
    "    \"\"\"\n",
    "    Read all sequences from a FASTA file.\n",
    "    If filter_non_canonical=True, discard any sequence containing non-standard AAs.\n",
    "    \"\"\"\n",
    "    seqs = []\n",
    "    with open(filepath) as f:\n",
    "        header = None\n",
    "        seq = \"\"\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\">\"):\n",
    "                if header is not None and seq:\n",
    "                    # Only keep this sequence if all residues are in our 20‐AA set,\n",
    "                    # when filter_non_canonical=True.\n",
    "                    if (not filter_non_canonical) or (set(seq) <= canonical_set):\n",
    "                        seqs.append(seq)\n",
    "                header = line\n",
    "                seq = \"\"\n",
    "            else:\n",
    "                seq += line\n",
    "        # Catch the last sequence\n",
    "        if header is not None and seq:\n",
    "            if (not filter_non_canonical) or (set(seq) <= canonical_set):\n",
    "                seqs.append(seq)\n",
    "    return seqs\n",
    "\n",
    "# Load ~70 folded PDB chains (filter non-canonical AA)\n",
    "pdb_seqs     = load_fasta(\"pdb_chains.fasta\",    filter_non_canonical=True)\n",
    "# Load ~13k DisProt sequences (allow non-canonical AA)\n",
    "disprot_seqs = load_fasta(\"disprot_13000.fasta\", filter_non_canonical=False)\n",
    "\n",
    "# ─── (C) Compute each sequence’s 7 global features ─────────────────────────────\n",
    "def compute_global_features(sequence):\n",
    "    \"\"\"\n",
    "    For a given AA sequence, compute a 7‐element array:\n",
    "      [mean_hydro_norm, mean_charge, mean_h_dh_a,\n",
    "       mean_norm_flex,  mean_pol_norm,  mean_arom_plus_helix,  mean_asa_norm]\n",
    "    by averaging per-residue aa_properties.\n",
    "    \"\"\"\n",
    "    props = []\n",
    "    for aa in sequence:\n",
    "        if aa in aa_properties:\n",
    "            props.append(aa_properties[aa])\n",
    "    if not props:\n",
    "        # If the sequence is empty or has no canonical AA, return zeros\n",
    "        return np.zeros(7)\n",
    "    return np.mean(np.vstack(props), axis=0)\n",
    "\n",
    "# Build feature matrix (one row per protein) and label vector\n",
    "all_features = []\n",
    "all_labels   = []\n",
    "\n",
    "for seq in pdb_seqs:\n",
    "    all_features.append(compute_global_features(seq))\n",
    "    all_labels.append(1)  # 1 = folded (PDB)\n",
    "for seq in disprot_seqs:\n",
    "    all_features.append(compute_global_features(seq))\n",
    "    all_labels.append(0)  # 0 = disordered (DisProt)\n",
    "\n",
    "df_feat = pd.DataFrame(\n",
    "    all_features,\n",
    "    columns=[\n",
    "        \"hydro_norm\",        # normalized hydrophobicity\n",
    "        \"charge\",            # net charge\n",
    "        \"h_dh_a\",            # total H-bond donors + acceptors\n",
    "        \"norm_flex\",         # normalized flexibility\n",
    "        \"pol_norm\",          # normalized polarity\n",
    "        \"arom_plus_helix\",   # aromatic + helix propensity\n",
    "        \"asa_norm\"           # normalized ASA\n",
    "    ]\n",
    ")\n",
    "df_feat[\"label\"] = all_labels\n",
    "\n",
    "# ─── (D) Logistic Regression “Rule” Using Learned Weights ────────────────────\n",
    "# We previously trained a logistic model and obtained these weights:\n",
    "#   hydro_norm      → +9.149\n",
    "#   charge          → +3.051\n",
    "#   h_dh_a          → +2.034\n",
    "#   norm_flex       → –7.553\n",
    "#   pol_norm        → –6.521\n",
    "#   arom_plus_helix → +8.728\n",
    "#   asa_norm        → –7.629\n",
    "# Intercept = +0.131\n",
    "#\n",
    "# The sigmoid(score) = 1 / (1 + exp( – (intercept + Σ weight_i × feature_i) )).\n",
    "# We predict “folded” (PDB) if sigmoid(score) > 0.5.\n",
    "\n",
    "# Store weights and intercept in numpy arrays for easy dot‐product\n",
    "weights = np.array([\n",
    "    9.149,    # weight for hydro_norm\n",
    "    3.051,    # weight for charge\n",
    "    2.034,    # weight for h_dh_a\n",
    "   -7.553,    # weight for norm_flex\n",
    "   -6.521,    # weight for pol_norm\n",
    "    8.728,    # weight for arom_plus_helix\n",
    "   -7.629     # weight for asa_norm\n",
    "])\n",
    "intercept = 0.131\n",
    "\n",
    "# Compute “score” and predicted probability for each protein in df_feat\n",
    "# sigmoid(x) = 1/(1 + exp(–x))\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "# Extract feature matrix (N × 7)\n",
    "X = df_feat[[\n",
    "    \"hydro_norm\",\n",
    "    \"charge\",\n",
    "    \"h_dh_a\",\n",
    "    \"norm_flex\",\n",
    "    \"pol_norm\",\n",
    "    \"arom_plus_helix\",\n",
    "    \"asa_norm\"\n",
    "]].values\n",
    "\n",
    "# Compute raw scores: intercept + X ⋅ weights\n",
    "raw_scores = intercept + X.dot(weights)\n",
    "\n",
    "# Compute predicted probabilities of “PDB” (folded)\n",
    "probs_pdb = sigmoid(raw_scores)\n",
    "\n",
    "# Choose threshold = 0.5 for “PDB” vs. “DisProt”\n",
    "preds_05 = (probs_pdb > 0.5).astype(int)\n",
    "\n",
    "# ─── (E) Evaluate on the Entire Dataset ───────────────────────────────────────\n",
    "true_labels = df_feat[\"label\"].values\n",
    "\n",
    "print(\"Classification Report (Threshold = 0.5):\\n\")\n",
    "print(classification_report(true_labels, preds_05, target_names=[\"DisProt\",\"PDB\"]))\n",
    "\n",
    "cm = confusion_matrix(true_labels, preds_05)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm,\n",
    "    index=[\"Actual DisProt\", \"Actual PDB\"],\n",
    "    columns=[\"Pred DisProt\", \"Pred PDB\"]\n",
    ")\n",
    "print(\"Confusion Matrix (Threshold = 0.5):\\n\")\n",
    "print(cm_df)\n",
    "\n",
    "# ─── (F) Optionally, Adjust Threshold to Reduce False Positives ──────────────\n",
    "# Because PDB is very rare, you may want to require a higher probability (e.g., 0.7) \n",
    "# to call “PDB.” Simply do: preds_07 = (probs_pdb > 0.7).astype(int) and re‐evaluate.\n",
    "\n",
    "# Example at threshold = 0.7:\n",
    "preds_07 = (probs_pdb > 0.7).astype(int)\n",
    "print(\"\\n--- Threshold = 0.7 ---\")\n",
    "print(classification_report(true_labels, preds_07, target_names=[\"DisProt\",\"PDB\"]))\n",
    "cm_07 = confusion_matrix(true_labels, preds_07)\n",
    "cm_07_df = pd.DataFrame(\n",
    "    cm_07,\n",
    "    index=[\"Actual DisProt\", \"Actual PDB\"],\n",
    "    columns=[\"Pred DisProt\", \"Pred PDB\"]\n",
    ")\n",
    "print(\"Confusion Matrix (Threshold = 0.7):\\n\")\n",
    "print(cm_07_df)\n",
    "\n",
    "# ─── (G) (Optional) Inspect the Learned Weights ──────────────────────────────\n",
    "print(\"\\nLearned Logistic Weights:\")\n",
    "feature_names = [\n",
    "    \"hydro_norm\", \"charge\", \"h_dh_a\",\n",
    "    \"norm_flex\", \"pol_norm\", \"arom_plus_helix\", \"asa_norm\"\n",
    "]\n",
    "for name, w in zip(feature_names, weights):\n",
    "    print(f\"{name:15s} → {w:.3f}\")\n",
    "print(f\"Intercept: {intercept:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
